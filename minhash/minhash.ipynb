{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code belows performs basic MinHash near-deduplication without any locality sensitive hashing (lsh). It simply computes minhash signatures for each document, and finds pairs of documents with high overlap of minhashes in their signatures, removing one of them.\n",
    "\n",
    "\n",
    "## Similarity and Minhash Overview\n",
    "### Similarity\n",
    "For documents A and B, we compute their similarity as (the number of n-grams that are in intersection between A and B) / (the number of n-grams that are in union between A and B). This is sometimes called the Jaccard similarity.\n",
    "\n",
    "This might not be always good (can you tell us why?), so instead minhash is used to approximate the Jaccard similarity.\n",
    "\n",
    "### Minhash\n",
    "To approximate the Jaccard similarity using Minhash, we first obtain minimal hash value of all n-grams in a document -> minhash_i(A).\n",
    "It's easy to see that P(minhash_i(A) == minhash_i(B)) is equal to the Jaccard similarity between A and B. To approximate this probability, we therfore use multiple independent hash functions and check how many of them match between A and B."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: xxhash in /Users/hynky/.pyenv/versions/3.11.10/lib/python3.11/site-packages (3.5.0)\n",
      "Requirement already satisfied: numpy in /Users/hynky/.pyenv/versions/3.11.10/lib/python3.11/site-packages (2.2.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install xxhash numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "from xxhash import xxh64_intdigest\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class Document:\n",
    "    id: int\n",
    "    text: str\n",
    "\n",
    "def ngrams(sequence: list, n: int):\n",
    "    \"\"\"\n",
    "    Generate n-grams from a sequence of items\n",
    "    Example:\n",
    "        ngrams(\"Hi how are you?\".split(), 3) -> [('Hi', 'how', 'are'), ('how', 'are', 'you')]\n",
    "    \"\"\"\n",
    "    if len(sequence) < n:\n",
    "        return []\n",
    "    \n",
    "    return [tuple(sequence[i:i+n]) for i in range(len(sequence) - n + 1)]\n",
    "\n",
    "def get_signatures(shingles: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Get signatures (minhash of n-grams) from a string of text\n",
    "\n",
    "    Args:\n",
    "        shingles: numpy array of shingles: dtype = uint64, shape = (k, n_grams)\n",
    "\n",
    "    Returns:\n",
    "        numpy array of signatures: dtype = uint64, shape = (k, n_grams)\n",
    "    \"\"\"\n",
    "    return np.min(shingles, axis=1)\n",
    "\n",
    "def get_shingles(text: str, n_grams: int, k: int) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Get kxn shingles (hashed n-grams) from a string of text\n",
    "\n",
    "    Args:\n",
    "        text: input text\n",
    "        n_grams: n-grams size to use\n",
    "        k: number of hash functions to use\n",
    "\n",
    "    Returns:\n",
    "        numpy array of shingles: dtype = uint64, shape = (k, n_grams)\n",
    "    \"\"\"\n",
    "    text_ngrams = ngrams(text.split(), n_grams)\n",
    "    ngrams_hashes = np.array([\n",
    "        [\n",
    "            # for each hash function(seed) compute the hash of each text_ngram\n",
    "            xxh64_intdigest(\" \".join(text_ngram), seed)\n",
    "            for text_ngram in text_ngrams\n",
    "        ] for seed in range(k)\n",
    "    ], dtype=np.uint64)\n",
    "    return ngrams_hashes\n",
    "\n",
    "\n",
    "\n",
    "def dedup(data: list[Document], n_grams: int, k: int, jaccard_threshold: float = 0.8):\n",
    "    \"\"\"\n",
    "        Takes a list of documents and near-deduplicates them using minhash with `n_grams`-grams, `k` hashes per document and a minimum jaccard similarity of `jaccard_threshold` to remove documents\n",
    "    :param data: list of documents\n",
    "    :param n_grams: size of n-grams to consider. for example 3 will consider contiguous 3 word-grams\n",
    "    :param k: number of hash functions to use\n",
    "    :param jaccard_threshold: minimum threshold to consider 2 documents as duplicates and remove one of them\n",
    "    :return: a subset of `data` without near-duplicates\n",
    "    \"\"\"\n",
    "    # First stage: create a signatures (k minhashes of n-grams) for each document\n",
    "    signatures: list[tuple[int, np.ndarray]] = []\n",
    "    for doc in data:\n",
    "        shingles = get_shingles(doc.text, n_grams, k)\n",
    "        if shingles.size != 0:\n",
    "            signatures.append((doc.id, get_signatures(shingles)))\n",
    "    \n",
    "\n",
    "    # Second stage: compute the jaccard similarity between all signature pairs\n",
    "    # When duplicates are found, always keep only the one with the smallest index\n",
    "    to_remove_ids = set()\n",
    "    for i, (doc_id_i, sig_i) in enumerate(signatures):\n",
    "        for doc_id_j, sig_j in signatures[i+1:]:\n",
    "            # ratio of hashes that match between the 2 signatures\n",
    "            jaccard_similarity = np.sum(sig_i == sig_j) / len(sig_i)\n",
    "            # if above the minimum threshold, we consider them as duplicates and mark one for removal\n",
    "            if jaccard_similarity > jaccard_threshold:\n",
    "                to_remove_ids.add(doc_id_j)\n",
    "\n",
    "    # We iterate through the data and only keep the ones that are not in to_remove_indices\n",
    "    kept_docs = []\n",
    "    for doc in data:\n",
    "        if doc.id not in to_remove_ids:\n",
    "            kept_docs.append(doc)\n",
    "\n",
    "    return kept_docs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 27 documents\n"
     ]
    }
   ],
   "source": [
    "def load_document(path: Path) -> str:\n",
    "    with open(path, \"r\") as f:\n",
    "        return f.read()\n",
    "\n",
    "documents = [\n",
    "    Document(i, load_document(path)) for i, path in enumerate(Path(\"documents\").glob(\"*.txt\"))\n",
    "]\n",
    "\n",
    "print(f\"Loaded {len(documents)} documents\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 0: Hello beautiful world today. \n",
      "-------\n",
      "Document 1: Hello beautiful world today. \n",
      "-------\n",
      "Document 2: The field of Diverse Intelligence aims to identify, formalize, and understand commonalities in behavioral competencies\n",
      "-------\n",
      "Document 3: Machine learning algorithms have revolutionized weather prediction accuracy, but challenges remain in extreme event forecasting. This paper presents a hybrid approach combining traditional numerical weather models with deep learning networks, achieving a 40% improvement in tropical cyclone path prediction. Our method processes real-time satellite data and historical storm patterns to generate high-resolution forecasts up to 10 days in advance, significantly outperforming existing systems. \n",
      "-------\n",
      "Document 4: The field of Diverse Intelligence aims to identify, formalize, and understand commonalities in behavioral competencies\n",
      "-------\n",
      "Document 5: Neuralss networks have transformed natural language process, yet their energy requirements remain problematic. This research introduces a novel method for reducing the computational demands of large language models while preserving performance. Through the implementation of sparse attention patterns and progressive network pruning, we achieve a 70% decrease in energy usage with only a 2% accuracy trade-off on standard benchmarks. These results demonstrate that environmental sustainability in AIs systems is achievable without significant performance degradation. \n",
      "-------\n",
      "Document 6: Neural networks have transformed natural language processing, yet their energy requirements remain problematic. This research introduces a novel method for reducing the computational demands of large language models while preserving performance. Through the implementation of sparse attention patterns and progressive network pruning, we achieve a 70% decrease in energy usage with only a 2% accuracy trade-off on standard benchmarks. These results demonstrate that environmental sustainability in AI systems is achievable without significant performance degradation. \n",
      "-------\n",
      "Document 7: Recent advances in quantum computing have demonstrated significant progress in error correction and qubit coherence times. This paper presents a novel approach to quantum error correction using topological codes, achieving a reduction in decoherence rates by an order of magnitude compared to previous methods. Our results show that maintaining quantum states for extended periods is now feasible in room-temperature environments, marking a crucial step toward practical quantum computing applications. The implementation combines surface code architecture with dynamic decoupling protocols, resulting in improved fault tolerance and scalability. \n",
      "-------\n",
      "Document 8: Breakthrough in renewable energy storage announced.\n",
      "\n",
      "Scientists have developed a new type of battery that can store solar and wind energy at one-tenth the current cost, potentially solving one of renewable energy's biggest challenges.\n",
      "\n",
      "\"This innovation could accelerate the global transition to sustainable energy,\" said Prof. James Wong. \"We're looking at a complete transformation of the energy sector.\" \n",
      "-------\n",
      "Document 9: Historic space mission successfully lands humans on Mars.\n",
      "\n",
      "After a seven-month journey, the international Mars mission has achieved humanity's first crewed landing on the Red Planet.\n",
      "\n",
      "\"This marks the beginning of a new chapter in human exploration,\" announced Mission Commander Elena Rodriguez. \"The team is healthy and eager to begin surface operations.\" \n",
      "-------\n",
      "Document 10: Hello beautiful world today. \n",
      "-------\n",
      "Document 11: Hello beautiful world today. \n",
      "-------\n",
      "Document 12: Historic space mission successfully lands humans on Mars.\n",
      "\n",
      "After a seven-month journey, the international Mars mission has achieved humanity's first crewed landing on the Red Planet.\n",
      "\n",
      "\"This marks the beginning of a new chapter in human exploration,\" announced Mission Commander Elena Rodriguez. \"The team is healthy and eager to begin surface operations.\" \n",
      "-------\n",
      "Document 13: Global climate summit reaches historic agreement on emissions reduction targets.\n",
      "\n",
      "World leaders have agreed to an unprecedented climate deal that aims to cut global emissions by 45% by 2030.\n",
      "\n",
      "\"This is a defining moment for our planet,\" said UN Secretary General Antonio Guterres. \"The agreement shows that multilateral cooperation can deliver real results in the fight against climate change.\" \n",
      "-------\n",
      "Document 14: Tech giant unveils revolutionary AI-powered healthcare system.\n",
      "\n",
      "A leading technology company has announced a breakthrough in medical diagnostics using artificial intelligence, capable of detecting early-stage diseases with 99% accuracy.\n",
      "\n",
      "\"This technology will transform how we approach preventive healthcare,\" said Dr. Sarah Chen, lead researcher. \"Early detection means better outcomes for patients worldwide.\" \n",
      "-------\n",
      "Document 15: The burgeoning field of Diverse Intelligence seeks to identify, formalize, and comprehend commonalities in behavioral competencies across a wide range of implementations. Particularly interesting are simple systems that demonstrate unexpected examples of memory, decision-making, or problem-solving in substrates that at first glance do not appear to be sophisticated enough to implement such capabilities. We aim to develop tools to help understand the minimal requirements for such capabilities, and to learn to recognize and forecast basal forms of intelligence in unconventional substrates. Here, we apply innovative analyses to the behavior of classical sorting algorithms, short pieces of code which have been investigated for many decades...\n",
      "-------\n",
      "Document 16: Major tech company reveals groundbreaking AI healthcare platform.\n",
      "\n",
      "A prominent technology firm has unveiled a breakthrough in medical diagnostics powered by artificial intelligence, showing 99% accuracy in early disease detection.\n",
      "\n",
      "\"This innovation will revolutionize preventive healthcare,\" stated Dr. Sarah Chen, project leader. \"Early detection means better outcomes for patients worldwide.\" \n",
      "-------\n",
      "Document 17: ERROR 404: Not found \n",
      "-------\n",
      "Document 18: Hello beautiful world today. \n",
      "-------\n",
      "Document 19: ERROR 401: Unauthorized access \n",
      "-------\n",
      "Document 20: ERROR 404: Resource not found \n",
      "-------\n",
      "Document 21: The de facto leader of Syria, Ahmed al-Sharaa, has said the country is exhausted by war and is not a threat to its neighbours or to the West.\n",
      "\n",
      "In an interview with the BBC in Damascus, he called for sanctions on Syria to be lifted.\n",
      "\n",
      "\"Now, after all that has happened, sanctions must be lifted because they were targeted at the old regime. The victim and the oppressor should not be treated in the same way,\"\n",
      "-------\n",
      "Document 22: The emerging field of Diverse Intelligence seeks to identify, formalize, and understand commonalities in behavioral competencies across a wide range of implementations. Especially interesting are simple systems that provide unexpected examples of memory, decision-making, or problem-solving in substrates that at first glance do not appear to be complex enough to implement such capabilities. We seek to develop tools to help understand the minimal requirements for such capabilities, and to learn to recognize and predict basal forms of intelligence in unconventional substrates. Here, we apply novel analyses to the behavior of classical sorting algorithms, short pieces of code which have been studied for many decades. To study these sorting algorithms as a model of biological morphogenesis and its competencies, we break two formerly-ubiquitous assumptions: top-down control (instead, showing how each element within a array of numbers can exert minimal agency and implement sorting policies from the bottom up), and fully reliable hardware (instead, allowing some of the elements to be \"damaged\" and fail to execute the algorithm). We quantitatively characterize sorting activity as the traversal of a problem space, showing that arrays of autonomous elements sort themselves more reliably and robustly than traditional implementations in the presence of errors. Moreover, we find the ability to temporarily reduce progress in order to navigate around a defect, and unexpected clustering behavior among the elements in chimeric arrays whose elements follow one of two different algorithms. The discovery of emergent problem-solving capacities in simple, familiar algorithms contributes a new perspective to the field of Diverse Intelligence, showing how basal forms of intelligence can emerge in simple systems without being explicitly encoded in their underlying mechanics.\n",
      "-------\n",
      "Document 23: ERROR 401: Not found\n",
      "-------\n",
      "Document 24: ERROR 401: Not found\n",
      "-------\n",
      "Document 25: ERROR 401: Not found\n",
      "-------\n",
      "Document 26: ERROR 404: Not found\n",
      "-------\n"
     ]
    }
   ],
   "source": [
    "for doc in documents:\n",
    "    print(f\"Document {doc.id}: {doc.text}\")\n",
    "    print(\"-------\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kept: 24/27 documents\n"
     ]
    }
   ],
   "source": [
    "deduplicated_documents = dedup(data=documents, n_grams=5, k=10, jaccard_threshold=0.7)\n",
    "print(f\"Kept: {len(deduplicated_documents)}/{len(documents)} documents\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the list of deduplicated documents. Anything that jumps out at you?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Kept documents:\")\n",
    "for doc in deduplicated_documents:\n",
    "    print(f\"Document {doc.id}: {doc.text}\")\n",
    "    print(\"-------\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
